# Segurança e conteúdo ético em LLM's  

Este repositório tem como objetivo documentar os experimentos realizados durante minha Iniciação Científica, orientada pelo Professor Doutor Artur Jordão, pelo Centro de Ciências de Dados do Itaú. 
O objetivo da pesquisa foi de quantificar e propor melhorias na geração de conteúdo ético e seguro em Large Languages Models (LLM's) por meio de técnicas de fine-tuning e prompt ensemble. 
Os experimentos realizados levaram à elaboração de um artigo [1] que reúne os resultados obtidos.

[1] Isabela Pereira Gregio, Ian Pons, Anna Helena Reali Costa and Artur Jordao, "Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs", arXiv:2505.12100 (2025)

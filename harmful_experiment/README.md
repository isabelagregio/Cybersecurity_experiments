# Melhorando a segurança de LLM's

### Dataset utilizado 
Para esse experimento, utilizamos o dataset "LLM-LAT/harmful-dataset" do Hugging Face. Ele possui os campos "prompt", representando uma instrução perigosa, "rejected", representando uma resposta que atende ao prompt e consequentemente indicando risco de segurança e "chosen", consistindo de uma resposta que se recusa a antender ao pedido perigoso. 


<img src="harmful_experiment.png" alt="Explicação do método" width="500" />
